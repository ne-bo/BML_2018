{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.data_loaders import MnistDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_size = 100 \n",
    "code_gen = CodeGenerator(code_size, noise_size=code_size)\n",
    "encoder = Encoder(code_size)\n",
    "decoder = Decoder(code_size)\n",
    "disc_code = CodeDiscriminator(code_size)\n",
    "disc_img = ImageDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpu_use = 1\n",
    "device = torch.device('cuda:0' if n_gpu_use > 0 else 'cpu')\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "code_gen = code_gen.to(device)\n",
    "disc_code = disc_code.to(device)\n",
    "disc_img = disc_img.to(device)\n",
    "\n",
    "optimizer_enc = torch.optim.Adam(encoder.parameters(), lr=10e-4)\n",
    "optimizer_dec = torch.optim.Adam(decoder.parameters(), lr=10e-4)\n",
    "optimizer_disc_img = torch.optim.Adam(disc_img.parameters(), lr=10e-4)\n",
    "optimizer_disc_code = torch.optim.Adam(disc_code.parameters(), lr=10e-4)\n",
    "optimizer_code_gen = torch.optim.Adam(code_gen.parameters(), lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_loader = MnistDataLoader('mnist_data', batch_size=batch_size, shuffle=True, validation_split=0.2, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "traindataset = torchvision.datasets.MNIST('mnist_data', transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                                                                  torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "data_loader = torch.utils.data.dataloader.DataLoader(traindataset, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_G = torch.optim.Adam([encoder.parameters(), decoder.parameters()])\n",
    "# optimizer_D = torch.optim.Adam([disc_code.parameters(), disc_img.parameters()])\n",
    "\n",
    "dec_weight = 2\n",
    "\n",
    "cross_entropy_loss = torch.nn.BCELoss()\n",
    "mse_loss = torch.nn.MSELoss() \n",
    "\n",
    "def train_epoch():\n",
    "    enc_total_loss = 0\n",
    "    dec_total_loss = 0\n",
    "    disc_code_total_loss = 0\n",
    "    disc_img_total_loss = 0\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        cur_batch_size = data.shape[0]\n",
    "        # AAE phase\n",
    "        z = torch.randn((cur_batch_size, code_size)).to(device)\n",
    "#         code_gen.train(False)\n",
    "#         disc_img.train(False)\n",
    "#         encoder.train()\n",
    "#         disc_code.train()\n",
    "#         decoder.train()\n",
    "        \n",
    "#         optimizer_enc.zero_grad()\n",
    "#         optimizer_disc_code.zero_grad()\n",
    "#         optimizer_dec.zero_grad()\n",
    "\n",
    "        z_code = code_gen(z)\n",
    "        data_repr = encoder(data)\n",
    "        data_rec = decoder(data_repr)\n",
    "\n",
    "        loss_rec = mse_loss(disc_img(data_rec)[0], disc_img(data)[0].detach()) #.fmap\n",
    "        disc_code_input = torch.cat((z_code, data_repr))\n",
    "        disc_code_pred = disc_code(disc_code_input).reshape(2*cur_batch_size)\n",
    "        disc_code_target = torch.cat((torch.ones(cur_batch_size), torch.zeros(cur_batch_size))).to(device)\n",
    "\n",
    "        disc_code_gan_loss = cross_entropy_loss(disc_code_pred, disc_code_target)\n",
    "        enc_loss = loss_rec - disc_code_gan_loss\n",
    "\n",
    "        optimizer_enc.zero_grad()        \n",
    "        enc_loss.backward(retain_graph=True)\n",
    "        optimizer_enc.step()\n",
    "        enc_total_loss += enc_loss.data.cpu().numpy().item()\n",
    "\n",
    "        optimizer_disc_code.zero_grad()\n",
    "        disc_code_gan_loss.backward(retain_graph=True)\n",
    "        optimizer_disc_code.step()   \n",
    "        disc_code_total_loss += disc_code_gan_loss.data.cpu().numpy().item()\n",
    "\n",
    "        dec_loss = dec_weight*loss_rec\n",
    "        optimizer_dec.zero_grad()\n",
    "        dec_loss.backward(retain_graph=False)\n",
    "        optimizer_dec.step()\n",
    "        dec_total_loss += dec_loss.data.cpu().numpy().item()\n",
    "        \n",
    "        \n",
    "        # Prior improvement phase\n",
    "#         encoder.train(False)\n",
    "#         disc_code.train(False)\n",
    "#         code_gen.train()\n",
    "#         disc_img.train()\n",
    "#         decoder.train()\n",
    "        \n",
    "        z = torch.randn((cur_batch_size, code_size)).to(device)\n",
    "        z_code = code_gen(z)\n",
    "        x_sampled = decoder(z_code)\n",
    "        data_repr = encoder(data)\n",
    "        data_rec = decoder(data_repr)\n",
    "        \n",
    "        disc_img_input = torch.cat((x_sampled, data, data_rec))\n",
    "        disc_img_pred = disc_img(disc_img_input)[0].reshape(3*cur_batch_size)\n",
    "        disc_img_target = torch.cat((torch.zeros(cur_batch_size), torch.ones(cur_batch_size), torch.zeros(cur_batch_size))).to(device)\n",
    "        disc_img_gan_loss = cross_entropy_loss(disc_img_pred, disc_img_target)\n",
    "        \n",
    "        optimizer_disc_img.zero_grad()\n",
    "        optimizer_code_gen.zero_grad()\n",
    "        disc_img_gan_loss.backward(retain_graph=True)\n",
    "        optimizer_disc_img.step()\n",
    "        \n",
    "        disc_img_total_loss += disc_img_gan_loss.data.cpu().numpy().item()\n",
    "        \n",
    "        dec_loss = -disc_img_gan_loss\n",
    "        optimizer_dec.zero_grad()\n",
    "        dec_loss.backward(retain_graph=False)\n",
    "        optimizer_dec.step()\n",
    "        optimizer_code_gen.step()\n",
    "\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(((data_rec[1].data.cpu().numpy()+1)/2).reshape(28,28), cmap='gray')\n",
    "    plt.savefig('log_img/'+str(i)+'.png')\n",
    "    plt.show()\n",
    "    print(\"enc_total_loss:\", enc_total_loss)\n",
    "    print(\"dec_total_loss:\", dec_total_loss)\n",
    "    print(\"disc_code_total_loss:\", disc_code_total_loss)\n",
    "    print(\"disc_img_total_loss:\", disc_img_total_loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_norm_grad(model):\n",
    "    cur_norm = 0\n",
    "    for par in model.parameters():\n",
    "        cur_norm = par.grad.norm()\n",
    "    print(model.__class__.__name__, cur_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_rec: 0.3631129562854767\n",
      "disc_code_gan_loss: 3.9460774132749066e-05\n",
      "dec_loss: 0.3631129562854767\n",
      "Decoder tensor(1.00000e-02 *\n",
      "       3.4719, device='cuda:0')\n",
      "disc_img_gan_loss: 0.00044393076677806675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-2:\n",
      "Process Process-7:\n",
      "Process Process-1:\n",
      "Process Process-8:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-4:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fcf0a79ae10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3023) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-599470378d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mdisc_img_gan_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0moptimizer_disc_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mdisc_img_total_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdisc_img_gan_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mdec_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdisc_img_gan_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enc_total_loss = 0\n",
    "dec_total_loss = 0\n",
    "disc_code_total_loss = 0\n",
    "disc_img_total_loss = 0\n",
    "\n",
    "\n",
    "dec_weight = 1\n",
    "\n",
    "cross_entropy_loss = torch.nn.BCELoss()\n",
    "mse_loss = torch.nn.MSELoss() \n",
    "\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(data_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    cur_batch_size = data.shape[0]\n",
    "    # AAE phase\n",
    "    z = torch.randn((cur_batch_size, code_size)).to(device)\n",
    "#     code_gen.train(False)\n",
    "#     disc_img.train(False)\n",
    "#     encoder.train()\n",
    "#     disc_code.train()\n",
    "#     decoder.train()\n",
    "#         optimizer_enc.zero_grad()\n",
    "#         optimizer_disc_code.zero_grad()\n",
    "#         optimizer_dec.zero_grad()\n",
    "    z_code = code_gen(z)\n",
    "    data_repr = encoder(data)\n",
    "    data_rec = decoder(data_repr)\n",
    "\n",
    "    loss_rec = 2*torch.norm(disc_img(data_rec)[2]-disc_img(data)[2].detach())/cur_batch_size#mse_loss(disc_img(data_rec)[2], disc_img(data)[2].detach()) #.fmap\n",
    "    disc_code_input = torch.cat((z_code, data_repr))\n",
    "    disc_code_pred = disc_code(disc_code_input).reshape(2*cur_batch_size)\n",
    "    disc_code_target = torch.cat((torch.ones(cur_batch_size), torch.zeros(cur_batch_size))).to(device)\n",
    "\n",
    "    print(\"loss_rec:\", loss_rec.item())\n",
    "    \n",
    "    disc_code_gan_loss = cross_entropy_loss(disc_code_pred, disc_code_target)\n",
    "    print(\"disc_code_gan_loss:\", disc_code_gan_loss.item())\n",
    "    enc_loss = loss_rec - disc_code_gan_loss\n",
    "\n",
    "    optimizer_code_gen.zero_grad()\n",
    "    optimizer_enc.zero_grad()\n",
    "    enc_loss.backward(retain_graph=True)\n",
    "    optimizer_enc.step()\n",
    "    enc_total_loss += enc_loss.data.cpu().numpy().item()\n",
    "\n",
    "    optimizer_disc_code.zero_grad()\n",
    "    disc_code_gan_loss.backward(retain_graph=True)\n",
    "    optimizer_disc_code.step()   \n",
    "    disc_code_total_loss += disc_code_gan_loss.data.cpu().numpy().item()\n",
    "    dec_loss = dec_weight*loss_rec\n",
    "    print(\"dec_loss:\", dec_loss.item())  \n",
    "\n",
    "    optimizer_dec.zero_grad()\n",
    "    dec_loss.backward(retain_graph=True)\n",
    "    get_model_norm_grad(decoder)\n",
    "    optimizer_dec.step()\n",
    "    dec_total_loss += dec_loss.data.cpu().numpy().item()\n",
    "    \n",
    "    # Prior improvement phase\n",
    "#     encoder.train(False)\n",
    "#     disc_code.train(False)\n",
    "#     code_gen.train()\n",
    "#     disc_img.train()\n",
    "#     decoder.train()\n",
    "\n",
    "    z = torch.randn((cur_batch_size, code_size)).to(device)\n",
    "    z_code = code_gen(z)\n",
    "    x_sampled = decoder(z_code)\n",
    "    data_repr = encoder(data)\n",
    "    data_rec = decoder(data_repr)\n",
    "\n",
    "    disc_img_input = torch.cat((x_sampled, data, data_rec))\n",
    "    disc_img_pred = disc_img(disc_img_input)[0].reshape(3*cur_batch_size)\n",
    "    disc_img_target = torch.cat((torch.zeros(cur_batch_size), torch.ones(cur_batch_size), torch.zeros(cur_batch_size))).to(device)\n",
    "    disc_img_gan_loss = 10*cross_entropy_loss(disc_img_pred, disc_img_target)\n",
    "    print(\"disc_img_gan_loss:\", disc_img_gan_loss.item())\n",
    "    optimizer_disc_img.zero_grad()\n",
    "    disc_img_gan_loss.backward(retain_graph=True)\n",
    "    optimizer_disc_img.step()\n",
    "    disc_img_total_loss += disc_img_gan_loss.data.cpu().numpy().item()\n",
    "\n",
    "    dec_loss = -10*disc_img_gan_loss\n",
    "    optimizer_dec.zero_grad()\n",
    "    dec_loss.backward(retain_graph=False)\n",
    "    get_model_norm_grad(decoder)\n",
    "    optimizer_dec.step() \n",
    "\n",
    "    plt.imshow(((data_rec[0].data.cpu().numpy()+1)/2).reshape(28, 28), cmap='gray')\n",
    "    plt.show()\n",
    "    print(dec_loss)\n",
    "    clear_output(wait=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_total_loss: 80.97048492357135\n",
      "dec_total_loss: 194.34900653886143\n",
      "disc_code_total_loss: 16.2040184582861\n",
      "disc_img_total_loss: 7.44602172388295\n",
      "\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-11:\n",
      "Process Process-15:\n",
      "Process Process-9:\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "Process Process-14:\n",
      "Process Process-16:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-10:\n",
      "Process Process-13:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f8a7d91e518>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 4926) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-59811a1de145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"disc_code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f1d07ec3cebc>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mcur_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# AAE phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    train_epoch()\n",
    "    torch.save(encoder, \"encoder\")\n",
    "    torch.save(decoder, \"decoder\")\n",
    "    torch.save(disc_code, \"disc_code\")\n",
    "    torch.save(disc_img, \"disc_img\")\n",
    "    torch.save(code_gen, \"code_gen\")\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in data_loader:\n",
    "    x_enc = encoder(x.cuda())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rec = decoder(x_enc[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in data_loader:\n",
    "    x_rec = decoder(encoder(x.cuda()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           1.6887,  2.6178, -0.2078, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  0.6831,  1.9942,  1.9942,\n",
       "           2.6178,  1.0013, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242,  0.6450,  2.1978,  2.7706,  2.7833,  2.7833,\n",
       "           1.4723, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.0806,  2.7960,  2.7833,  2.7833,  1.9051,  0.6450,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.0806,  2.2614,  2.7960,  2.7833,  0.8868, -0.2460, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.2587,\n",
       "           2.3505,  2.7960,  2.7197,  0.8104, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.8613,\n",
       "           2.7833,  2.7833,  0.8104, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.2941,\n",
       "           2.7833,  2.6815, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6450,  2.7069,\n",
       "           2.7833,  1.1159, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.9942,  2.7833,\n",
       "           2.1087, -0.3351,  0.9377,  1.4850,  0.9250,  0.0213, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  1.1414,  2.7960,  2.4142,\n",
       "           0.0213,  1.7141,  2.8215,  2.7960,  2.7960,  1.9942, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  0.0340,  2.7960,  2.7833,  0.7341,\n",
       "           0.6450,  2.6560,  2.7960,  2.7833,  2.7833,  1.9814, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.3478,  1.6378,  2.7960,  1.1286,  0.5304,\n",
       "           2.7069,  2.7833,  2.7960,  2.7833,  1.8669,  0.2249, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242,  0.7341,  2.7833,  2.6687,  0.1740,  1.5232,\n",
       "           2.7833,  2.7833,  2.7960,  1.7269, -0.3351, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.3649,  2.6178,  2.7833,  1.3577,  1.9305,  2.7451,\n",
       "           2.7833,  2.7833,  2.7960,  0.3777, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  1.2050,  2.7960,  2.7960,  2.8088,  2.7960,  2.7960,\n",
       "           2.7960,  2.7960,  2.2742, -0.0806, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  1.1923,  2.7833,  2.7833,  2.7960,  2.7833,  2.7833,\n",
       "           2.0705,  1.1541, -0.0806, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.4031,  2.3378,  2.7833,  2.7960,  2.1342,  0.5049,\n",
       "          -0.3351, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.1867,  2.7833,  2.7833,  2.1087, -0.1569, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.0424,  2.3378,  2.7833, -0.1951, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb02ec6d240>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(((x_rec[0].data.cpu().numpy()+1)/2).reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1., device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rec[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.15692005,  0.61950225,  1.523207  ,  1.2050011 ,\n",
       "         0.6831434 ,  2.5796502 ,  2.4778244 ,  0.5304046 , -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.29693064,  2.1596186 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,\n",
       "         2.8087585 ,  2.8087585 ,  2.8087585 ,  2.401455  , -0.05509418,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.25874594,  2.4650962 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,\n",
       "         2.8087585 ,  2.3759985 ,  2.8087585 ,  2.8087585 ,  0.30129635,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296,  0.8740668 ,  2.083249  ,  1.5359352 ,  0.8613386 ,\n",
       "        -0.2842024 , -0.27147415,  2.8087585 ,  2.8214867 ,  0.30129635,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296,  0.74678457,  2.8087585 ,  2.401455  , -0.30965886,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296,  1.803228  ,  2.8087585 ,  1.4341093 , -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.20783298,\n",
       "         1.5995764 ,  2.7960303 ,  2.8087585 ,  1.103175  , -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.20783298, -0.16964827,  0.05945994,  1.0522621 ,  2.0450644 ,\n",
       "         2.8087585 ,  2.8087585 ,  2.2996292 , -0.05509418, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296,  0.3522093 ,  1.8414128 ,\n",
       "         2.6560197 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,\n",
       "         2.8087585 ,  2.7705739 ,  0.32675284, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296,  0.6831434 ,  2.8087585 ,\n",
       "         2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,\n",
       "         2.8087585 ,  2.7578456 ,  0.1994705 , -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.20783298,  2.6560197 ,\n",
       "         2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,  2.6942043 ,\n",
       "         2.732389  ,  2.8087585 ,  0.67041516, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296,  0.18674228,\n",
       "         0.61950225,  0.61950225,  1.0777186 ,  0.61950225, -0.09327888,\n",
       "         0.98862094,  2.8087585 ,  1.0522621 , -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "         0.04673171,  2.7069325 ,  1.8923256 , -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.38602826, -0.3987565 , -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296,  2.1468904 ,  1.9305104 , -0.41148472, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296,  0.67041516,  1.7650434 , -0.15692005, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "         0.30129635,  2.5923786 ,  2.5541937 , -0.20783298, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296,  1.3450117 ,  2.8087585 ,  2.185075  , -0.16964827,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.08055065,\n",
       "         2.5032809 ,  2.8087585 ,  1.7014022 , -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296,  0.02127524,  2.6305633 ,  2.8087585 ,  2.3887267 ,\n",
       "         1.9941516 ,  0.8740668 ,  0.64495873,  1.1795444 ,  2.5796502 ,\n",
       "         2.8087585 ,  2.8087585 ,  0.67041516, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296,  0.6831434 ,  2.5796502 ,  2.8087585 ,\n",
       "         2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,\n",
       "         2.8087585 ,  2.783302  ,  0.39039403, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.15692005,  1.1286315 ,\n",
       "         2.3759985 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,\n",
       "         2.2105315 ,  0.17401403, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.05509418,  0.7595128 ,  1.5868481 ,  2.5923786 ,  1.9814233 ,\n",
       "        -0.27147415, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296],\n",
       "       [-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        -0.42421296, -0.42421296, -0.42421296]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].data.cpu().numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f32f65dc940>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[1].data.cpu().numpy().reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_gpu_use = 1\n",
    "device = torch.device('cuda:0' if n_gpu_use > 0 else 'cpu')\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "code_gen = code_gen.to(device)\n",
    "disc_code = disc_code.to(device)\n",
    "disc_img = disc_img.to(device)\n",
    "\n",
    "dec_weight = 2\n",
    "\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "mse_loss = torch.nn.MSELoss() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(data_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # AAE phase\n",
    "    z = torch.randn((batch_size, 8)).to(device)\n",
    "    code_gen.train(False)\n",
    "    disc_img.train(False)\n",
    "    encoder.train()\n",
    "    disc_code.train()\n",
    "    decoder.train()\n",
    "\n",
    "    z_code = code_gen(z)\n",
    "    data_repr = encoder(data)\n",
    "    data_rec = decoder(data_repr)\n",
    "    loss_rec = mse_loss(disc_img(data_rec)[0], disc_img(data)[0].detach()) #.fmap\n",
    "    disc_code_input = torch.cat((z_code, data_repr))\n",
    "    disc_code_pred = disc_code(disc_code_input)\n",
    "    disc_code_target = torch.cat((torch.ones(batch_size), torch.zeros(batch_size))).long().to(device)\n",
    "    break \n",
    "    disc_code_gan_loss = cross_entropy_loss(disc_code_pred, disc_code_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/generic/THCTensorCopy.c:70",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    398\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_number_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSCALE_FORMAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0m_min_log_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_min_log_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mmin_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mpos_inf_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/generic/THCTensorCopy.c:70"
     ]
    }
   ],
   "source": [
    "cross_entropy_loss(disc_code_pred, disc_code_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4957]]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_img(data_rec)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/generic/THCTensorCopy.c:70",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    398\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_number_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSCALE_FORMAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0m_min_log_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_min_log_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mmin_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mpos_inf_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/generic/THCTensorCopy.c:70"
     ]
    }
   ],
   "source": [
    "cross_entropy_loss(disc_code_pred, disc_code_target.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rec.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
